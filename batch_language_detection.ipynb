{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import copy\n",
    "import textwrap\n",
    "\n",
    "# cost per token for GPT4 8K\n",
    "prompt_token_cost = 0.03/1000\n",
    "generation_token_cost = 0.06/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating system prompt and user promot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = os.getenv(\"MODEL\")\n",
    "\n",
    "user_messages = [\n",
    "    \"GPT-3 (Generative Pre-trained Transformer 3) - OpenAI's powerful language model capable of writing like a human\",  \n",
    "    \"DALL-E - OpenAI's AI system that can create images from textual descriptions\",  \n",
    "    \"वोडाफोन को आप शिकायत के लिए 199 पर कॉल कर सकते हैं। इसके अलावा आप 9820098200 पर भी फोन कर सकते हैं। इन दोनों नंबर पर प्रति 3 मिनट 50 पैस चार्ज लगेंगे।\"\n",
    "]\n",
    "\n",
    "system_message = '''\n",
    "You are an helpful AI assistant that identifies the language into \"English\" or \"Non English\".\n",
    "###Important :\n",
    "Do not add any additional information.\n",
    "Make sure to complete all elements of the array'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English', 'English', 'Non English']\n",
      "Time taken for execution :  4.454633712768555\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAI(\n",
    "        api_version=os.getenv(\"API_VERSION\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"API_KEY\")\n",
    "    )\n",
    "\n",
    "responses = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, user_message in enumerate(user_messages):\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    result = completion.choices[0].message.content\n",
    "    responses.append(result)\n",
    "\n",
    "end_time = time.time()\n",
    "e2e_time = end_time - start_time\n",
    "\n",
    "print(responses)\n",
    "print(\"Time taken for execution : \", e2e_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[\"English\", \"English\", \"Non English\"]', 4.454633712768555)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aoai_call(system_message,prompt, model):\n",
    "    client = AzureOpenAI(\n",
    "        api_version=os.getenv(\"API_VERSION\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"API_KEY\")\n",
    "    )\n",
    "\n",
    "    # start_time = time.time()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # end_time = time.time()\n",
    "    # e2e_time = end_time - start_time\n",
    "\n",
    "    result=json.loads(completion.model_dump_json(indent=2))\n",
    "    completion_text=result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    return completion_text, e2e_time\n",
    "\n",
    "aoai_call(system_message, \n",
    "          json.dumps([user_messages]), model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 1.467106819152832 seconds\n",
      "['AI', 'AI', 'SCIENCE', 'AI', 'SCIENCE', 'AI', 'AI', 'AI', 'SCIENCE', 'SCIENCE', 'AI', 'AI', 'AI', 'AI', 'SCIENCE', 'AI']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "async def fetch(session, system_message, user_message):\n",
    "    url = f'{os.getenv(\"AZURE_ENDPOINT\")}/openai/deployments/gpt-4/chat/completions?api-version={os.getenv(\"API_VERSION\")}'\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": os.getenv(\"API_KEY\")\n",
    "    }  \n",
    "    data = {\n",
    "        \"model\": \"gpt-4\",  # Adjust the model as needed\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    async with session.post(url, json=data, headers=headers) as response:\n",
    "        return await response.json()\n",
    "\n",
    "async def main(system_message, user_messages):\n",
    "    api_call_batch_size = 16\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        tasks = []\n",
    "        responses = []\n",
    "        for i, user_message in enumerate(user_messages):\n",
    "            task = asyncio.create_task(fetch(session, system_message, user_message))\n",
    "            tasks.append(task)\n",
    "            if len(tasks) >= api_call_batch_size: \n",
    "                responses.extend(await asyncio.gather(*tasks))\n",
    "                tasks = []\n",
    "        responses.extend(await asyncio.gather(*tasks))  # Process the last batch\n",
    "        return responses\n",
    "\n",
    "system_message = '''\n",
    "You are an helpful AI assistant that identifies the language into \"English\" or \"Non-English\". \n",
    "###Important :\n",
    "Do not add any additional information'''\n",
    "\n",
    "start = time.time()\n",
    "responses_async = await main(system_message, user_messages)\n",
    "end = time.time()\n",
    "\n",
    "run_time = end - start\n",
    "print(f\"Total time taken: {run_time} seconds\")\n",
    "# responses\n",
    "response_content = []\n",
    "for i in range(len(responses_async)):\n",
    "    try:\n",
    "        response_content.append(responses_async[i][\"choices\"][0][\"message\"][\"content\"])\n",
    "    except:\n",
    "        pass\n",
    "print(response_content)\n",
    "print(len(response_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(user_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
